{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Am I The Asshole? - Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearchit(pipe, pipe_params, X, y, cv=5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=42)\n",
    "    gs = GridSearchCV(pipe, param_grid=pipe_params, cv=cv)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print_scores(gs)\n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(gs):\n",
    "    print(f'best score: {gs.best_score_}')\n",
    "    #print(f'best estimator: {gs.best_estimator_}')\n",
    "    print(f'train score: {gs.score(X_train, y_train)}')\n",
    "    print(f'test score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/final_4.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "title             0\n",
       "selftext          0\n",
       "total_comments    0\n",
       "vote              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>total_comments</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>euqrvj</td>\n",
       "      <td>AITA for expecting my husband's help as soon a...</td>\n",
       "      <td>I spend all day home with kids age 5 and 7. Ru...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>euqlxk</td>\n",
       "      <td>AITA for holding a grudge for 10 years with my...</td>\n",
       "      <td>This story may be mild compared to what you ca...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>euqhqt</td>\n",
       "      <td>AITA for not letting my son go to a non-vegan ...</td>\n",
       "      <td>My son (Eddie) recently started Grade 1 last S...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>euq28u</td>\n",
       "      <td>AITA for forcing my son to work out and go out...</td>\n",
       "      <td>My son is the laziest kid I've ever met and re...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>euq0ce</td>\n",
       "      <td>AITA for stealing my moms money to buy clothes?</td>\n",
       "      <td>Am I the asshole for stealing my moms money to...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  euqrvj  AITA for expecting my husband's help as soon a...   \n",
       "1  euqlxk  AITA for holding a grudge for 10 years with my...   \n",
       "2  euqhqt  AITA for not letting my son go to a non-vegan ...   \n",
       "3  euq28u  AITA for forcing my son to work out and go out...   \n",
       "4  euq0ce    AITA for stealing my moms money to buy clothes?   \n",
       "\n",
       "                                            selftext  total_comments  vote  \n",
       "0  I spend all day home with kids age 5 and 7. Ru...            21.0     1  \n",
       "1  This story may be mild compared to what you ca...            20.0     1  \n",
       "2  My son (Eddie) recently started Grade 1 last S...            57.0     1  \n",
       "3  My son is the laziest kid I've ever met and re...            16.0     1  \n",
       "4  Am I the asshole for stealing my moms money to...            25.0     1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a df with Balanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_assholes = df.loc[df['vote'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_assholes = df_all_assholes.vote.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_assholes = df.loc[df['vote'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_assholes_sample = df_no_assholes.sample(n=num_assholes, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.concat([df_all_assholes, df_no_assholes_sample], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    857\n",
       "0    857\n",
       "Name: vote, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.vote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1714, 6)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index             0\n",
       "id                0\n",
       "title             0\n",
       "selftext          0\n",
       "total_comments    0\n",
       "vote              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize, Lemmatize and Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list_of_tokenized_colvals(col, sw=stop_words, t=tokenizer):\n",
    "    tokenized_col = [t.tokenize(txt) for txt in col]\n",
    "    tokenized_col_no_stop = []\n",
    "    if sw:\n",
    "        for i in tokenized_col:\n",
    "            no_stop = [word for word in i if word not in sw]\n",
    "            tokenized_col_no_stop.append(no_stop)\n",
    "        return tokenized_col_no_stop\n",
    "    return tokenized_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes list of tokens lists\n",
    "def make_lemma_stems_df(tokenized_texts_list, prefix):\n",
    "    lemmatized = []\n",
    "    stemmed = []\n",
    "    for i in tokenized_texts_list:\n",
    "        lemma_tokens = {}\n",
    "        lemmas = [lemmatizer.lemmatize(word) for word in i]\n",
    "        lemma_tokens['lemmas_'+ prefix] = ' '.join(lemmas)\n",
    "        lemmatized.append(lemma_tokens)\n",
    "\n",
    "        stem_tokens = {}\n",
    "        stems = [stemmer.stem(word) for word in i]\n",
    "        stem_tokens['stems_'+ prefix] = ' '.join(stems)\n",
    "        stemmed.append(stem_tokens)\n",
    "    stem_lemma_df = pd.concat([pd.DataFrame(stemmed), pd.DataFrame(lemmatized)], axis=1)\n",
    "    return stem_lemma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tokens = make_list_of_tokenized_colvals(balanced_df['title'])\n",
    "title_lemma_stems_df = make_lemma_stems_df(title_tokens, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tokens_with_sws = make_list_of_tokenized_colvals(balanced_df['title'], sw=False)\n",
    "title_lemma_stems_df_no_sws = make_lemma_stems_df(title_tokens_with_sws, 'title_with_sw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.concat([balanced_df, title_lemma_stems_df_no_sws], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "selftext_tokens = make_list_of_tokenized_colvals(balanced_df['selftext'])\n",
    "selftext_lemma_stems_df = make_lemma_stems_df(selftext_tokens, 'selftext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.concat([balanced_df, title_lemma_stems_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.concat([balanced_df, selftext_lemma_stems_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make column that combines title and selftext data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df['title_selftext_stems'] = balanced_df['stems_selftext'] + balanced_df['stems_title']\n",
    "balanced_df['title_selftext_lemmas'] = balanced_df['lemmas_selftext'] + balanced_df['lemmas_title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>total_comments</th>\n",
       "      <th>vote</th>\n",
       "      <th>stems_title</th>\n",
       "      <th>lemmas_title</th>\n",
       "      <th>stems_selftext</th>\n",
       "      <th>lemmas_selftext</th>\n",
       "      <th>stems_title_with_sw</th>\n",
       "      <th>lemmas_title_with_sw</th>\n",
       "      <th>title_selftext_stems</th>\n",
       "      <th>title_selftext_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>euqrvj</td>\n",
       "      <td>AITA for expecting my husband's help as soon a...</td>\n",
       "      <td>I spend all day home with kids age 5 and 7. Ru...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>aita expect husband help soon get home</td>\n",
       "      <td>AITA expecting husband help soon get home</td>\n",
       "      <td>I spend day home kid age 5 7 run around ton ex...</td>\n",
       "      <td>I spend day home kid age 5 7 Running around to...</td>\n",
       "      <td>aita for expect my husband s help as soon as h...</td>\n",
       "      <td>AITA for expecting my husband s help a soon a ...</td>\n",
       "      <td>I spend day home kid age 5 7 run around ton ex...</td>\n",
       "      <td>I spend day home kid age 5 7 Running around to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>euqlxk</td>\n",
       "      <td>AITA for holding a grudge for 10 years with my...</td>\n",
       "      <td>This story may be mild compared to what you ca...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>aita hold grudg 10 year S O</td>\n",
       "      <td>AITA holding grudge 10 year S O</td>\n",
       "      <td>thi stori may mild compar get aita post but ye...</td>\n",
       "      <td>This story may mild compared get AITA post But...</td>\n",
       "      <td>aita for hold a grudg for 10 year with my S O</td>\n",
       "      <td>AITA for holding a grudge for 10 year with my S O</td>\n",
       "      <td>thi stori may mild compar get aita post but ye...</td>\n",
       "      <td>This story may mild compared get AITA post But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>euqhqt</td>\n",
       "      <td>AITA for not letting my son go to a non-vegan ...</td>\n",
       "      <td>My son (Eddie) recently started Grade 1 last S...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1</td>\n",
       "      <td>aita let son go non vegan birthday parti</td>\n",
       "      <td>AITA letting son go non vegan birthday party</td>\n",
       "      <td>My son eddi recent start grade 1 last septemb ...</td>\n",
       "      <td>My son Eddie recently started Grade 1 last Sep...</td>\n",
       "      <td>aita for not let my son go to a non vegan birt...</td>\n",
       "      <td>AITA for not letting my son go to a non vegan ...</td>\n",
       "      <td>My son eddi recent start grade 1 last septemb ...</td>\n",
       "      <td>My son Eddie recently started Grade 1 last Sep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>euq28u</td>\n",
       "      <td>AITA for forcing my son to work out and go out...</td>\n",
       "      <td>My son is the laziest kid I've ever met and re...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>aita forc son work go outsid</td>\n",
       "      <td>AITA forcing son work go outside</td>\n",
       "      <td>My son laziest kid I ever met recent I enough ...</td>\n",
       "      <td>My son laziest kid I ever met recently I enoug...</td>\n",
       "      <td>aita for forc my son to work out and go outsid</td>\n",
       "      <td>AITA for forcing my son to work out and go out...</td>\n",
       "      <td>My son laziest kid I ever met recent I enough ...</td>\n",
       "      <td>My son laziest kid I ever met recently I enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>euq0ce</td>\n",
       "      <td>AITA for stealing my moms money to buy clothes?</td>\n",
       "      <td>Am I the asshole for stealing my moms money to...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>aita steal mom money buy cloth</td>\n",
       "      <td>AITA stealing mom money buy clothes</td>\n",
       "      <td>Am I asshol steal mom money get cloth I live c...</td>\n",
       "      <td>Am I asshole stealing mom money get clothes I ...</td>\n",
       "      <td>aita for steal my mom money to buy cloth</td>\n",
       "      <td>AITA for stealing my mom money to buy clothes</td>\n",
       "      <td>Am I asshol steal mom money get cloth I live c...</td>\n",
       "      <td>Am I asshole stealing mom money get clothes I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id                                              title  \\\n",
       "0      0  euqrvj  AITA for expecting my husband's help as soon a...   \n",
       "1      1  euqlxk  AITA for holding a grudge for 10 years with my...   \n",
       "2      2  euqhqt  AITA for not letting my son go to a non-vegan ...   \n",
       "3      3  euq28u  AITA for forcing my son to work out and go out...   \n",
       "4      4  euq0ce    AITA for stealing my moms money to buy clothes?   \n",
       "\n",
       "                                            selftext  total_comments  vote  \\\n",
       "0  I spend all day home with kids age 5 and 7. Ru...            21.0     1   \n",
       "1  This story may be mild compared to what you ca...            20.0     1   \n",
       "2  My son (Eddie) recently started Grade 1 last S...            57.0     1   \n",
       "3  My son is the laziest kid I've ever met and re...            16.0     1   \n",
       "4  Am I the asshole for stealing my moms money to...            25.0     1   \n",
       "\n",
       "                                stems_title  \\\n",
       "0    aita expect husband help soon get home   \n",
       "1               aita hold grudg 10 year S O   \n",
       "2  aita let son go non vegan birthday parti   \n",
       "3              aita forc son work go outsid   \n",
       "4            aita steal mom money buy cloth   \n",
       "\n",
       "                                   lemmas_title  \\\n",
       "0     AITA expecting husband help soon get home   \n",
       "1               AITA holding grudge 10 year S O   \n",
       "2  AITA letting son go non vegan birthday party   \n",
       "3              AITA forcing son work go outside   \n",
       "4           AITA stealing mom money buy clothes   \n",
       "\n",
       "                                      stems_selftext  \\\n",
       "0  I spend day home kid age 5 7 run around ton ex...   \n",
       "1  thi stori may mild compar get aita post but ye...   \n",
       "2  My son eddi recent start grade 1 last septemb ...   \n",
       "3  My son laziest kid I ever met recent I enough ...   \n",
       "4  Am I asshol steal mom money get cloth I live c...   \n",
       "\n",
       "                                     lemmas_selftext  \\\n",
       "0  I spend day home kid age 5 7 Running around to...   \n",
       "1  This story may mild compared get AITA post But...   \n",
       "2  My son Eddie recently started Grade 1 last Sep...   \n",
       "3  My son laziest kid I ever met recently I enoug...   \n",
       "4  Am I asshole stealing mom money get clothes I ...   \n",
       "\n",
       "                                 stems_title_with_sw  \\\n",
       "0  aita for expect my husband s help as soon as h...   \n",
       "1      aita for hold a grudg for 10 year with my S O   \n",
       "2  aita for not let my son go to a non vegan birt...   \n",
       "3     aita for forc my son to work out and go outsid   \n",
       "4           aita for steal my mom money to buy cloth   \n",
       "\n",
       "                                lemmas_title_with_sw  \\\n",
       "0  AITA for expecting my husband s help a soon a ...   \n",
       "1  AITA for holding a grudge for 10 year with my S O   \n",
       "2  AITA for not letting my son go to a non vegan ...   \n",
       "3  AITA for forcing my son to work out and go out...   \n",
       "4      AITA for stealing my mom money to buy clothes   \n",
       "\n",
       "                                title_selftext_stems  \\\n",
       "0  I spend day home kid age 5 7 run around ton ex...   \n",
       "1  thi stori may mild compar get aita post but ye...   \n",
       "2  My son eddi recent start grade 1 last septemb ...   \n",
       "3  My son laziest kid I ever met recent I enough ...   \n",
       "4  Am I asshol steal mom money get cloth I live c...   \n",
       "\n",
       "                               title_selftext_lemmas  \n",
       "0  I spend day home kid age 5 7 Running around to...  \n",
       "1  This story may mild compared get AITA post But...  \n",
       "2  My son Eddie recently started Grade 1 last Sep...  \n",
       "3  My son laziest kid I ever met recently I enoug...  \n",
       "4  Am I asshole stealing mom money get clothes I ...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression with TfidfVectorizer and CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Features, CountVectorize and TfidVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = balanced_df['stems_selftext']\n",
    "y = balanced_df['vote']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set TfidfVec Pipline, Run Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(solver = 'liblinear'))\n",
    "])\n",
    "pipe_params = {\n",
    "    'tf__max_features': [800, 1000, 1500, 2000],\n",
    "    'tf__min_df': [1, 2, 3],\n",
    "    'tf__max_df': [.6, .7, .9],\n",
    "    'tf__stop_words': [None, stop_words],\n",
    "    'tf__ngram_range': [(1,2), (1,3)],\n",
    "    'lr__C': [.03, .1, .2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.5859922178988327\n",
      "best estimator: Pipeline(memory=None,\n",
      "         steps=[('tf',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=0.7, max_features=1500,\n",
      "                                 min_df=3, ngram_range=(1, 2), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words={'a', 'about', 'above', 'after',\n",
      "                                             'again', 'against', 'ain', 'all',\n",
      "                                             'a...\n",
      "                                 strip_accents=None, sublinear_tf=False,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=0.2, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)\n",
      "train score: 0.7867704280155642\n",
      "test score: 0.5407925407925408\n"
     ]
    }
   ],
   "source": [
    "gridsearchit(pipe, pipe_params, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Cvec Pipline, Run Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(solver = 'liblinear'))\n",
    "])\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [500, 900, 1200],\n",
    "    'cvec__min_df': [1, 2, 3],\n",
    "    'cvec__max_df': [.6, .7, .9],\n",
    "    'cvec__stop_words': [None, stop_words],\n",
    "    'cvec__ngram_range': [(1,2)],\n",
    "    'lr__C': [.03, .1, .2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.5595330739299611\n",
      "best estimator: Pipeline(memory=None,\n",
      "         steps=[('cvec',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=0.6,\n",
      "                                 max_features=500, min_df=2, ngram_range=(1, 2),\n",
      "                                 preprocessor=None,\n",
      "                                 stop_words={'a', 'about', 'above', 'after',\n",
      "                                             'again', 'against', 'ain', 'all',\n",
      "                                             'am', 'an', 'and', 'any', 'are',\n",
      "                                             '...\n",
      "                                             'couldn', \"couldn't\", ...},\n",
      "                                 strip_accents=None,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, vocabulary=None)),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=0.03, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=100,\n",
      "                                    multi_class='warn', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)\n",
      "train score: 0.7712062256809339\n",
      "test score: 0.5221445221445221\n"
     ]
    }
   ],
   "source": [
    "gridsearchit(pipe, pipe_params, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = balanced_df['stems_title']\n",
    "y = balanced_df['vote']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'rf__n_estimators': [100, 150, 200],\n",
    "    'rf__max_depth': [None, 1, 3, 5],\n",
    "    'rf__max_features' : [None, 2, 3, 4] # none is bagging, a number can take a random subset of features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.5805447470817121\n",
      "best estimator: Pipeline(memory=None,\n",
      "         steps=[('cvec',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=1.0,\n",
      "                                 max_features=None, min_df=1,\n",
      "                                 ngram_range=(1, 1), preprocessor=None,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, vocabulary=Non...\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=None,\n",
      "                                        max_features=3, max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=150, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "train score: 0.9976653696498055\n",
      "test score: 0.5174825174825175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cvec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features=3, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=150, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearchit(pipe, pipe_params, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Column Transformer with TfidfVectorizer and Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "        [(\"cvec\", CountVectorizer())\n",
    "         #(\"norm2\", Normalizer(norm='l1')\n",
    "          ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                   0\n",
       "id                      0\n",
       "title                   0\n",
       "selftext                0\n",
       "total_comments          0\n",
       "vote                    0\n",
       "stems_title             0\n",
       "lemmas_title            0\n",
       "stems_selftext          0\n",
       "lemmas_selftext         0\n",
       "stems_title_with_sw     0\n",
       "lemmas_title_with_sw    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenabrentano/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = balanced_df[['stems_title', 'total_comments']]\n",
    "y = balanced_df['vote']\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['total_comments']\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='median'))])\n",
    "\n",
    "categorical_features = ['stems_title']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('cvec', CountVectorizer())])\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[('tf', TfidfVectorizer(), 'stems_title')])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('ct', ct),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "\n",
    "grid_search_params = {'ct__tf__ngram_range': [],\n",
    "                      'classifier__solver':['liblinear']}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Column Transformer with TfidfVectorizer and RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "        [(\"cvec\", CountVectorizer())\n",
    "         #(\"norm2\", Normalizer(norm='l1')\n",
    "          ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                   0\n",
       "id                      0\n",
       "title                   0\n",
       "selftext                0\n",
       "total_comments          0\n",
       "vote                    0\n",
       "stems_title             0\n",
       "lemmas_title            0\n",
       "stems_selftext          0\n",
       "lemmas_selftext         0\n",
       "stems_title_with_sw     0\n",
       "lemmas_title_with_sw    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenabrentano/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = balanced_df[['stems_title', 'total_comments']]\n",
    "y = balanced_df['vote']\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['total_comments']\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='median'))])\n",
    "\n",
    "categorical_features = ['stems_title']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('cvec', CountVectorizer())])\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[('tf', TfidfVectorizer(), 'stems_title')])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('ct', ct),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "\n",
    "grid_search_params = {'ct__tf__ngram_range': [],\n",
    "                      'classifier__solver':['liblinear']}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
